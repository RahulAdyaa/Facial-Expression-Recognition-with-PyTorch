{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_M90-_f3k8m"
      },
      "source": [
        "# Dataset available at kaggle\n",
        "\n",
        "https://www.kaggle.com/jonathanoheix/face-expression-recognition-dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVZJB6C5vobN"
      },
      "source": [
        "\n",
        "Install libraries, packages and dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPaMVYICuTRa",
        "outputId": "01b68010-dc04-4674-b1d4-c1ee04b5c8a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Facial-Expression-Dataset'...\n",
            "remote: Enumerating objects: 34052, done.\u001b[K\n",
            "remote: Total 34052 (delta 0), reused 0 (delta 0), pack-reused 34052 (from 1)\u001b[K\n",
            "Receiving objects: 100% (34052/34052), 52.31 MiB | 46.54 MiB/s, done.\n",
            "Resolving deltas: 100% (4/4), done.\n",
            "Updating files: 100% (35887/35887), done.\n",
            "Collecting git+https://github.com/albumentations-team/albumentations\n",
            "  Cloning https://github.com/albumentations-team/albumentations to /tmp/pip-req-build-2ffrgqsb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/albumentations-team/albumentations /tmp/pip-req-build-2ffrgqsb\n",
            "  Resolved https://github.com/albumentations-team/albumentations to commit 2a793a1df0931d4ecf4fb3e4f183905e429c7736\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.2) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.2) (1.13.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.2) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.2) (2.10.6)\n",
            "Collecting albucore==0.0.23 (from albumentations==2.0.2)\n",
            "  Downloading albucore-0.0.23-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations==2.0.2) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations==2.0.2) (3.11.3)\n",
            "Collecting simsimd>=5.9.2 (from albucore==0.0.23->albumentations==2.0.2)\n",
            "  Downloading simsimd-6.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.0/66.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations==2.0.2) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations==2.0.2) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations==2.0.2) (4.12.2)\n",
            "Downloading albucore-0.0.23-py3-none-any.whl (14 kB)\n",
            "Downloading simsimd-6.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (632 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m632.7/632.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-2.0.2-py3-none-any.whl size=282372 sha256=127a435720fcc68a971d5d4d61ec2269133860c7de02a46884087e16b6199019\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3h_d_m9i/wheels/d8/87/c6/794399113ca308f93f3af45afd7d85eff07615a89a2b799e91\n",
            "Successfully built albumentations\n",
            "Installing collected packages: simsimd, albucore, albumentations\n",
            "  Attempting uninstall: albucore\n",
            "    Found existing installation: albucore 0.0.19\n",
            "    Uninstalling albucore-0.0.19:\n",
            "      Successfully uninstalled albucore-0.0.19\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.4.20\n",
            "    Uninstalling albumentations-1.4.20:\n",
            "      Successfully uninstalled albumentations-1.4.20\n",
            "Successfully installed albucore-0.0.23 albumentations-2.0.2 simsimd-6.2.1\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.14)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from timm) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from timm) (0.20.1+cu124)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.27.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->timm)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->timm)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->timm)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->timm)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->timm)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->timm)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->timm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->timm) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->timm) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2024.12.14)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (4.10.0.84)\n",
            "Collecting opencv-contrib-python\n",
            "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-contrib-python) (1.26.4)\n",
            "Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-contrib-python\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.10.0.84\n",
            "    Uninstalling opencv-contrib-python-4.10.0.84:\n",
            "      Successfully uninstalled opencv-contrib-python-4.10.0.84\n",
            "Successfully installed opencv-contrib-python-4.11.0.86\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/parth1620/Facial-Expression-Dataset.git\n",
        "!pip install -U git+https://github.com/albumentations-team/albumentations\n",
        "!pip install timm\n",
        "!pip install --upgrade opencv-contrib-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoVVdBpoweEk"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "creZrxH0vv20"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5604GKdwtAr"
      },
      "source": [
        "# Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dd6v8vyGwp3F"
      },
      "outputs": [],
      "source": [
        "TRAIN_IMG_FOLDER_PATH = '/content/Facial-Expression-Dataset/train/'\n",
        "VALID_IMG_FOLDER_PATH = '/content/Facial-Expression-Dataset/validation/'\n",
        "#LEARNING RATE\n",
        "LR=0.001\n",
        "BATCH_SIZE=32\n",
        "EPOCHS=15\n",
        "\n",
        "\n",
        "DEVICE='cuda'\n",
        "MODEL_NAME='efficientnet_b0'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wn5jWAF9xDUY"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvujfkVHxJ0V"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jqf-Ktqsx9WL"
      },
      "outputs": [],
      "source": [
        "train_augs=T.Compose([\n",
        "    #T.composwe -----> It ensures that the output of one transformation is passed as input to the next.\n",
        "    T.RandomHorizontalFlip(p=0.5), # randomly flips the image horizontally with .50% chance the image will be flipped. If the random number generated is less than 0.5, the image is flipped; otherwise, it remains unchanged.\n",
        "    T.RandomRotation(degrees=(-20,+20)),#This transformation rotates the image by a random angle.\n",
        "    T.ToTensor() #PIL(Python Imaging Library) / numpy array ---> torch tensor ->(image (h,w,channel)->(c,h,w)) , shift the position of channel\n",
        "\n",
        "])\n",
        "# We are using dynamic augmentation, which will not increase the data size\n",
        "valid_augs=T.Compose([\n",
        "    T.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmOazEVJN8xR"
      },
      "outputs": [],
      "source": [
        "trainset=ImageFolder(TRAIN_IMG_FOLDER_PATH,transform=train_augs)\n",
        "validset=ImageFolder(VALID_IMG_FOLDER_PATH,transform=valid_augs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eznRIKAzzuCj",
        "outputId": "2a30c530-6bb1-4815-9953-c3ee489b668e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total no. of examples in trainset : 28821\n",
            "Total no. of examples in validset : 7066\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total no. of examples in trainset : {len(trainset)}\")\n",
        "print(f\"Total no. of examples in validset : {len(validset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtoA4SRny_vz",
        "outputId": "0c1bd234-2dda-4878-889f-bfde07ef3a51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n"
          ]
        }
      ],
      "source": [
        "print(trainset.class_to_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "0-b1SLqNw91J",
        "outputId": "d0b333ba-5278-4698-d5a4-5f19b761efd3"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "image,label = trainset[8090]\n",
        "plt.imshow(image.permute(1,2,0)) #(h,w,c)\n",
        "plt.title(label)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjVmykAGy0Sh"
      },
      "source": [
        "# Load Dataset into Batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egpuikhHymP7"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pea8G9-HzhuZ"
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(trainset , batch_size=BATCH_SIZE , shuffle=True)\n",
        "validloader = DataLoader(validset,batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjf9oeOBzihh",
        "outputId": "6e356186-e3bf-4292-a912-8a0b9373dc20"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total no. of batches in trainloader : 901\n",
            "Total no. of batches in validloader : 221\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total no. of batches in trainloader : {len(trainloader)}\")\n",
        "print(f\"Total no. of batches in validloader : {len(validloader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtVSVVj-zp1C",
        "outputId": "2ca497fd-63d5-4b37-a17a-658f7259994f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "One image batch shape : torch.Size([32, 3, 48, 48])\n",
            "One label batch shape : torch.Size([32])\n"
          ]
        }
      ],
      "source": [
        "for images,labels in trainloader:\n",
        "  break;\n",
        "\n",
        "\n",
        "\n",
        "print(f\"One image batch shape : {images.shape}\")#32,3,48,48-> no. of images in 1 batch, channel size , image size(48,48)\n",
        "print(f\"One label batch shape : {labels.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQvgvbKu0TUG"
      },
      "source": [
        "# Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqwWf5-O0SWP"
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6uJZmUw0XJX"
      },
      "outputs": [],
      "source": [
        "class FaceModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FaceModel , self).__init__()\n",
        "\n",
        "    self.eff_net = timm.create_model('efficientnet_b0',pretrained=True,num_classes=7)\n",
        "\n",
        "    #pretrained=True: Indicates that the model should be loaded with weights pre-trained on a dataset (commonly ImageNet)\n",
        "    #num_classes=7: Sets the final layer to output 7 logits, representing 7 classes for classification (e.g., facial expression recognition)\n",
        "    #output are logits without any softmax or sigmoid activation\n",
        "\n",
        "\n",
        "  def forward(self , images , labels = None):\n",
        "    logits=self.eff_net(images) # without any sigmoid , or softmax applied on it on the final layer\n",
        "\n",
        "    if labels!=None:\n",
        "      loss=nn.CrossEntropyLoss()(logits,labels)\n",
        "      return logits , loss\n",
        "\n",
        "    return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgp5OjEO0_2w",
        "outputId": "7218c1d3-6080-4a32-c1bc-bf8b87d90f7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "FaceModel(\n",
              "  (eff_net): EfficientNet(\n",
              "    (conv_stem): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNormAct2d(\n",
              "      32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): Sequential(\n",
              "        (0): DepthwiseSeparableConv(\n",
              "          (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (6): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (aa): Identity()\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn2): BatchNormAct2d(\n",
              "      1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "    (classifier): Linear(in_features=1280, out_features=7, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model=FaceModel()\n",
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzDb6TdaCpF5"
      },
      "source": [
        "# Create Train and Eval Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLQVQA0PVjX8"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "#tqdm is a Python library used to display progress bars in loops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esp-tSrxTiPX"
      },
      "outputs": [],
      "source": [
        "def multiclass_accuracy(y_pred,y_true):\n",
        "    top_p,top_class = y_pred.topk(1,dim = 1)\n",
        "    equals = top_class == y_true.view(*top_class.shape)\n",
        "    return torch.mean(equals.type(torch.FloatTensor))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBim_pZxColX"
      },
      "outputs": [],
      "source": [
        "def train_fn(model,dataloader,optimizer,current_epo):\n",
        "  model.train()\n",
        "  total_loss=0\n",
        "  total_acc=0\n",
        "  tk=tqdm(dataloader , desc=\"EPOCH\"+\"[TRAIN]\"+str(current_epo+1)+\"/\"+str(EPOCHS))\n",
        "  #This line creates a progress bar using tqdm to track the progress of the training loop over the dataloader.\n",
        "\n",
        "\n",
        "  for t,data in enumerate(tk):\n",
        "    images,labels = data\n",
        "    images ,labels =images.to(DEVICE),labels.to(DEVICE) #Transfer to GPU\n",
        "    #images, labels = images.to(DEVICE), labels.to(DEVICE): Moves both the images and labels to the device specified by DEVICE (usually a GPU if available).\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    #PyTorch accumulates gradients by default.\n",
        "\n",
        "    logits,loss = model(images,labels)\n",
        "    loss.backward()\n",
        "    #This updates the model's parameters based on the gradients computed during loss.backward().\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss+=loss.item()\n",
        "    total_acc+=multiclass_accuracy(logits,labels)\n",
        "    tk.set_postfix({'loss':'%6f' %float(total_loss / (t+1)),\n",
        "                    'acc':'%6f' %float(total_acc / (t+1))})\n",
        "\n",
        "  return total_loss/len(dataloader),total_acc/len(dataloader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODT8B4BieJb1"
      },
      "outputs": [],
      "source": [
        "def eval_fn(model,dataloader,current_epo):\n",
        "  model.eval()\n",
        "  total_loss=0\n",
        "  total_acc=0\n",
        "  tk=tqdm(dataloader , desc=\"EPOCH\"+\"[VALID]\"+str(current_epo+1)+\"/\"+str(EPOCHS))\n",
        "\n",
        "  for t,data in enumerate(tk):\n",
        "    images,labels = data\n",
        "    images ,labels =images.to(DEVICE),labels.to(DEVICE) #Transfer to GPU\n",
        "\n",
        "\n",
        "    logits,loss = model(images,labels)\n",
        "\n",
        "\n",
        "    total_loss+=loss.item()\n",
        "    total_acc+=multiclass_accuracy(logits,labels)\n",
        "    tk.set_postfix({'loss':'%6f' %float(total_loss / (t+1)),\n",
        "                    'acc':'%6f' %float(total_acc / (t+1))})\n",
        "\n",
        "  return total_loss/len(dataloader),total_acc/len(dataloader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2YsWQvsXiKG"
      },
      "source": [
        "# Create Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbKd9D7pWeM_"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(),lr=LR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8yzdLmLXkC-",
        "outputId": "2a55b11e-0f09-49c9-cd35-d49635443211"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]1/15: 100%|██████████| 901/901 [01:06<00:00, 13.45it/s, loss=1.871509, acc=0.379152]\n",
            "EPOCH[VALID]1/15: 100%|██████████| 221/221 [00:07<00:00, 29.21it/s, loss=1.320128, acc=0.498967]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Best wiights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]2/15: 100%|██████████| 901/901 [00:49<00:00, 18.05it/s, loss=1.313333, acc=0.497860]\n",
            "EPOCH[VALID]2/15: 100%|██████████| 221/221 [00:06<00:00, 32.36it/s, loss=1.157562, acc=0.564969]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Best wiights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]3/15: 100%|██████████| 901/901 [00:48<00:00, 18.53it/s, loss=1.199444, acc=0.546157]\n",
            "EPOCH[VALID]3/15: 100%|██████████| 221/221 [00:06<00:00, 35.09it/s, loss=1.098372, acc=0.581796]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Best wiights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]4/15: 100%|██████████| 901/901 [00:49<00:00, 18.15it/s, loss=1.144477, acc=0.568200]\n",
            "EPOCH[VALID]4/15: 100%|██████████| 221/221 [00:07<00:00, 28.51it/s, loss=1.076064, acc=0.597383]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Best wiights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]5/15: 100%|██████████| 901/901 [00:48<00:00, 18.42it/s, loss=1.102350, acc=0.582210]\n",
            "EPOCH[VALID]5/15: 100%|██████████| 221/221 [00:07<00:00, 29.99it/s, loss=1.053899, acc=0.604105]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Best wiights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]6/15: 100%|██████████| 901/901 [00:47<00:00, 18.92it/s, loss=1.071856, acc=0.595892]\n",
            "EPOCH[VALID]6/15: 100%|██████████| 221/221 [00:06<00:00, 32.74it/s, loss=1.074505, acc=0.595186]\n",
            "EPOCH[TRAIN]7/15: 100%|██████████| 901/901 [00:48<00:00, 18.65it/s, loss=1.039878, acc=0.610149]\n",
            "EPOCH[VALID]7/15: 100%|██████████| 221/221 [00:06<00:00, 35.93it/s, loss=1.054946, acc=0.604703]\n",
            "EPOCH[TRAIN]8/15: 100%|██████████| 901/901 [00:48<00:00, 18.75it/s, loss=1.014038, acc=0.619880]\n",
            "EPOCH[VALID]8/15: 100%|██████████| 221/221 [00:06<00:00, 32.16it/s, loss=1.029316, acc=0.615265]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Best wiights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]9/15: 100%|██████████| 901/901 [00:53<00:00, 16.92it/s, loss=0.990951, acc=0.632938]\n",
            "EPOCH[VALID]9/15: 100%|██████████| 221/221 [00:07<00:00, 31.13it/s, loss=1.005466, acc=0.623727]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Best wiights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]10/15: 100%|██████████| 901/901 [00:53<00:00, 16.74it/s, loss=0.956064, acc=0.639024]\n",
            "EPOCH[VALID]10/15: 100%|██████████| 221/221 [00:06<00:00, 33.29it/s, loss=0.997132, acc=0.629753]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Best wiights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]11/15: 100%|██████████| 901/901 [00:52<00:00, 17.10it/s, loss=0.934294, acc=0.653541]\n",
            "EPOCH[VALID]11/15: 100%|██████████| 221/221 [00:06<00:00, 33.68it/s, loss=0.995683, acc=0.636976]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Best wiights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]12/15: 100%|██████████| 901/901 [00:52<00:00, 17.18it/s, loss=0.909005, acc=0.658131]\n",
            "EPOCH[VALID]12/15: 100%|██████████| 221/221 [00:07<00:00, 30.65it/s, loss=0.992111, acc=0.636541]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Best wiights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]13/15: 100%|██████████| 901/901 [00:49<00:00, 18.11it/s, loss=0.872146, acc=0.676882]\n",
            "EPOCH[VALID]13/15: 100%|██████████| 221/221 [00:06<00:00, 36.14it/s, loss=0.978495, acc=0.645123]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved Best wiights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "EPOCH[TRAIN]14/15: 100%|██████████| 901/901 [00:47<00:00, 18.89it/s, loss=0.847619, acc=0.683141]\n",
            "EPOCH[VALID]14/15: 100%|██████████| 221/221 [00:06<00:00, 32.71it/s, loss=1.007180, acc=0.638031]\n",
            "EPOCH[TRAIN]15/15: 100%|██████████| 901/901 [00:47<00:00, 19.04it/s, loss=0.820659, acc=0.694936]\n",
            "EPOCH[VALID]15/15: 100%|██████████| 221/221 [00:06<00:00, 34.81it/s, loss=1.003970, acc=0.639619]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "best_valid_loss=np.Inf\n",
        "\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "  train_loss,train_acc = train_fn(model,trainloader,optimizer,i) # i is curent EPOCH\n",
        "  valid_loss,valid_acc = eval_fn(model,validloader,i)\n",
        "\n",
        "  if valid_loss<best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(),\"best-weights.pt\")\n",
        "    print(\"Saved Best wiights\")\n",
        "    best_valid_loss = valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D9d-NDvekPEW"
      },
      "outputs": [],
      "source": [
        "#Model's Prediction: The model generates predictions (logits or probabilities).\n",
        "#Loss Calculation: The predicted values are compared to the true values using the loss function.\n",
        "#Loss Feedback: The loss is used to compute the gradients, which tell us how to adjust the weights to improve the model’s predictions.\n",
        "# Parameter Update: The optimizer uses the gradients to update the model’s parameters (weights and biases) to minimize the loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjiklrErXkZ6"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iozgi4xhLNg",
        "outputId": "4836c013-18d9-45ae-9152-9ad5abaf5e1f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-44-ade1cbfb1c04>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('/content/best-weights.pt'))\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torchvision import transforms as T\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "model = FaceModel()\n",
        "model.load_state_dict(torch.load('/content/best-weights.pt'))\n",
        "model.eval()\n",
        "model.to(DEVICE)\n",
        "\n",
        "\n",
        "inference_transforms = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "])\n",
        "\n",
        "def predict_image(image_path):\n",
        "    # image = Image.open('/content/happy.jpg')\n",
        "    # image = Image.open('/content/happy.jpg')\n",
        "    image = Image.open('/content/sad.jpg')\n",
        "    image = inference_transforms(image).unsqueeze(0).to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        logits = model(image)\n",
        "        probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
        "        predicted_class = torch.argmax(probabilities, dim=1).item()\n",
        "\n",
        "\n",
        "    class_names = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
        "    predicted_class_name = class_names[predicted_class]\n",
        "\n",
        "    return predicted_class_name, probabilities\n",
        "\n",
        "\n",
        "image_path = 'img_path'\n",
        "predicted_label, probabilities = predict_image(image_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_QZvnUGXmOf",
        "outputId": "a435ad80-f23a-4444-e9b3-c48e6665bf1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predicted Class: Neutral\n",
            "Probabilities: tensor([[0.0579, 0.0437, 0.1361, 0.1975, 0.0788, 0.0541, 0.4320]],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(f\"Predicted Class: {predicted_label}\")\n",
        "print(f\"Probabilities: {probabilities}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
